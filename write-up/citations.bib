@misc{splatterImage,
      title={Splatter Image: Ultra-Fast Single-View 3D Reconstruction}, 
      author={Stanislaw Szymanowicz and Christian Rupprecht and Andrea Vedaldi},
      year={2024},
      eprint={2312.13150},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.13150}, 
}
@misc{pointCloud,
      title={Learning to Recover 3D Scene Shape from a Single Image}, 
      author={Wei Yin and Jianming Zhang and Oliver Wang and Simon Niklaus and Long Mai and Simon Chen and Chunhua Shen},
      year={2020},
      eprint={2012.09365},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2012.09365}, 
}
@misc{mesh,
      title={Mesh R-CNN}, 
      author={Georgia Gkioxari and Jitendra Malik and Justin Johnson},
      year={2020},
      eprint={1906.02739},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1906.02739}, 
}
@misc{nerf,
      title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis}, 
      author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
      year={2020},
      eprint={2003.08934},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2003.08934}, 
}
@misc{triplane,
      title={Efficient Geometry-aware 3D Generative Adversarial Networks}, 
      author={Eric R. Chan and Connor Z. Lin and Matthew A. Chan and Koki Nagano and Boxiao Pan and Shalini De Mello and Orazio Gallo and Leonidas Guibas and Jonathan Tremblay and Sameh Khamis and Tero Karras and Gordon Wetzstein},
      year={2022},
      eprint={2112.07945},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.07945}, 
}
@misc{objaversexl,
      title={Objaverse-XL: A Universe of 10M+ 3D Objects}, 
      author={Matt Deitke and Ruoshi Liu and Matthew Wallingford and Huong Ngo and Oscar Michel and Aditya Kusupati and Alan Fan and Christian Laforte and Vikram Voleti and Samir Yitzhak Gadre and Eli VanderBilt and Aniruddha Kembhavi and Carl Vondrick and Georgia Gkioxari and Kiana Ehsani and Ludwig Schmidt and Ali Farhadi},
      year={2023},
      eprint={2307.05663},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2307.05663}, 
}
@misc{objaverse,
      title={Objaverse: A Universe of Annotated 3D Objects}, 
      author={Matt Deitke and Dustin Schwenk and Jordi Salvador and Luca Weihs and Oscar Michel and Eli VanderBilt and Ludwig Schmidt and Kiana Ehsani and Aniruddha Kembhavi and Ali Farhadi},
      year={2022},
      eprint={2212.08051},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.08051}, 
}
@misc{triplanebasedmodel,
      title={LRM: Large Reconstruction Model for Single Image to 3D}, 
      author={Yicong Hong and Kai Zhang and Jiuxiang Gu and Sai Bi and Yang Zhou and Difan Liu and Feng Liu and Kalyan Sunkavalli and Trung Bui and Hao Tan},
      year={2024},
      eprint={2311.04400},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2311.04400}, 
}
@inProceedings{xu2019disn,
  title={DISN: Deep Implicit Surface Network for High-quality Single-view 3D Reconstruction},
  author={Xu, Qiangeng and Wang, Weiyue and Ceylan, Duygu and Mech, Radomir and Neumann, Ulrich},
  booktitle={NeurIPS},
  year={2019}
}
@article{ShapeNet,
  author       = {Angel X. Chang and
                  Thomas A. Funkhouser and
                  Leonidas J. Guibas and
                  Pat Hanrahan and
                  Qi{-}Xing Huang and
                  Zimo Li and
                  Silvio Savarese and
                  Manolis Savva and
                  Shuran Song and
                  Hao Su and
                  Jianxiong Xiao and
                  Li Yi and
                  Fisher Yu},
  title        = {ShapeNet: An Information-Rich 3D Model Repository},
  journal      = {CoRR},
  volume       = {abs/1512.03012},
  year         = {2015},
  url          = {http://arxiv.org/abs/1512.03012},
  eprinttype    = {arXiv},
  eprint       = {1512.03012},
  timestamp    = {Fri, 25 Oct 2024 13:31:18 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/ChangFGHHLSSSSX15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@InProceedings{Bae2021,
    title   = {Estimating and Exploiting the Aleatoric Uncertainty in Surface Normal Estimation},
    author  = {Gwangbin Bae and Ignas Budvytis and Roberto Cipolla},
    booktitle = {International Conference on Computer Vision (ICCV)},
    year = {2021}                         
}
@inproceedings{NYUv2,
  author    = {Nathan Silberman, Derek Hoiem, Pushmeet Kohli and Rob Fergus},
  title     = {Indoor Segmentation and Support Inference from RGBD Images},
  booktitle = {ECCV},
  year      = {2012}
}
@inproceedings{qi2018geonet,
  title={Geonet: Geometric neural network for joint depth and surface normal estimation},
  author={Qi, Xiaojuan and Liao, Renjie and Liu, Zhengzhe and Urtasun, Raquel and Jia, Jiaya},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={283--291},
  year={2018}
}
@article{qi2020geonet++,
  title={GeoNet++: Iterative Geometric Neural Network with Edge-Aware Refinement for Joint Depth and Surface Normal Estimation},
  author={Qi, Xiaojuan and Liu, Zhengzhe and Liao, Renjie and Torr, Philip HS and Urtasun, Raquel and Jia, Jiaya},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2020},
  publisher={IEEE}
}
@inproceedings{dai2017scannet,
    title={ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes},
    author={Dai, Angela and Chang, Angel X. and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
    booktitle = {Proc. Computer Vision and Pattern Recognition (CVPR), IEEE},
    year = {2017}
}
@article{huang2019framenet,
  title={FrameNet: Learning Local Canonical Frames of 3D Surfaces from a Single RGB Image},
  author={Huang, Jingwei and Zhou, Yichao and Funkhouser, Thomas and Guibas, Leonidas},
  journal={arXiv preprint arXiv:1903.12305},
  year={2019}
}
@incollection{vifIntro,
title = {Chapter 10 - A study on the relationship between depth map quality and stereoscopic image quality using upsampled depth maps},
editor = {Leonidas Deligiannidis and Hamid R. Arabnia},
booktitle = {Emerging Trends in Image Processing, Computer Vision and Pattern Recognition},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {149-160},
year = {2015},
isbn = {978-0-12-802045-6},
doi = {https://doi.org/10.1016/B978-0-12-802045-6.00010-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128020456000107},
author = {Saeed Mahmoudpour and Manbae Kim},
keywords = {Correlation, Depth map, Stereoscopic image, Subjective assessment, Upsampling},
abstract = {Recent advances in 3D technology have made the need for reliable quality evaluation of synthesized virtual views. Using RGB image and the corresponding depth map, a synthesized view can be constructed. Depth map upsampling has gained much interest following the release of time-of-flight cameras. As upsampling can yield artifacts on sharp edges like ringing artifacts and jagged edges near the depth map boundaries, it will degrade the final reconstructed stereoscopic image quality. In this article, several upsampling methods are applied to depth maps. Then, diverse full-reference and no-reference quality assessment tools are utilized to measure the quality of depth maps obtained from selected upsampling approaches. Furthermore, subjective test is performed to determine the quality of stereoscopic images reconstructed from upsampled depth maps. Finally, the relation between subjective assessment and each objective quality assessment is investigated using correlation coefficients. The evaluation results introduce the objective quality assessment tools that can correctly render human judgement.}
}
@article{vifMetrics,
title = {Survey of natural image enhancement techniques: Classification, evaluation, challenges, and perspectives},
journal = {Digital Signal Processing},
volume = {127},
pages = {103547},
year = {2022},
issn = {1051-2004},
doi = {https://doi.org/10.1016/j.dsp.2022.103547},
url = {https://www.sciencedirect.com/science/article/pii/S1051200422001646},
author = {Xinwei Liu and Marius Pedersen and Renfang Wang},
keywords = {Image enhancement, Image quality metric, Visual quality, Database},
abstract = {Image enhancement is an essential technique used in many imaging applications. The main motivation of image enhancement is processing an image to be more suitable for specific utilization. Various image enhancement methods have been proposed in the existing literature. On the one hand, a variety of enhancement techniques make the classification more complex. On the other hand, the lack of image quality metrics specifically designed for enhanced images and the number of enhanced image quality databases as well as subjective data (ground truth) is limited, making the evaluation process difficult. This survey aims to guide the image enhancement research community to fill the above-mentioned gap and develop better and robust enhancement techniques. This survey 1) summarizes previous surveys of image enhancement techniques and existing classifications; 2) classifies the amount of techniques and analyzes their components, including how the performance has been evaluated; 3) surveys and recommends image quality metrics and databases that were designed for enhanced images; 4) discusses the challenges for image enhancement and its evaluation issues; and 5) proposes perspectives for the development of future image enhancement algorithms. This survey mainly focuses on image enhancement techniques that improve the perceived quality of natural images.}
}

@misc{Gatis_rembg_2025,
  author =       {Daniel Gatis},
  title =        {rembg},
  howpublished = {\url{https://github.com/danielgatis/rembg}},
  year =         {2025},
  note =         {Version 2.0.66}
}

@inproceedings{kim2022inspyrenet,
  title={Revisiting Image Pyramid Structure for High Resolution Salient Object Detection},
  author={Kim, Taehun and Kim, Kunhee and Lee, Joonyeong and Cha, Dongmin and Lee, Jiho and Kim, Daijin},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  pages={108--124},
  year={2022}
}

@article{zheng2024birefnet,
  title={Bilateral Reference for High-Resolution Dichotomous Image Segmentation},
  author={Zheng, Peng and Gao, Dehong and Fan, Deng-Ping and Liu, Li and Laaksonen, Jorma and Ouyang, Wanli and Sebe, Nicu},
  journal={CAAI Artificial Intelligence Research},
  volume = {3},
  pages = {9150038},
  year={2024}
}

@misc{wu2019detectron2,
  author =       {Yuxin Wu and Alexander Kirillov and Francisco Massa and
                  Wan-Yen Lo and Ross Girshick},
  title =        {Detectron2},
  howpublished = {\url{https://github.com/facebookresearch/detectron2}},
  year =         {2019}
}

@article{kirillov2023segany,
  title={Segment Anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Doll{\'a}r, Piotr and Girshick, Ross},
  journal={arXiv:2304.02643},
  year={2023}
}