{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e2a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args\n",
    "in_folder = \"/content/SRN/\"\n",
    "out_folder = \"/content/SRN/\"\n",
    "\n",
    "hf_repo_name = \"MVP-Group-Project/srn_cars_priors\"\n",
    "\n",
    "git_token = \"\"\n",
    "hf_token = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05086d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /content/\n",
    "!git clone https://\"{git_token}\"@github.com/Kacper-M-Michalik/3dgs-priors.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e730f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from huggingface_hub import login, HfApi\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2aa2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create venv for each prior model\n",
    "!python3 -m venv /content/models/depth --without-pip\n",
    "!python3 -m venv /content/models/normal --without-pip\n",
    "\n",
    "# Have to manually install pip to correctly build venvs on colab\n",
    "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
    "!/content/models/depth/bin/python3 get-pip.py\n",
    "!/content/models/normal/bin/python3 get-pip.py\n",
    "\n",
    "# Verify venv's work\n",
    "!/content/models/depth/bin/pip --version\n",
    "!/content/models/normal/bin/pip --version\n",
    "\n",
    "!ls -l /content/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae82e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup models\n",
    "\n",
    "# Depth\n",
    "!/content/models/depth/bin/pip install -r /content/3dgs-priors/geometry-priors/depth_requirements.txt\n",
    "\n",
    "# Normals\n",
    "!git clone https://github.com/baegwangbin/surface_normal_uncertainty.git /content/3dgs-priors/geometry-priors/surface_normal_uncertainty/\n",
    "!mkdir /content/3dgs-priors/geometry-priors/surface_normal_uncertainty/checkpoints/\n",
    "!gdown 1lOgY9sbMRW73qNdJze9bPkM2cmfA8Re- -O /content/3dgs-priors/geometry-priors/surface_normal_uncertainty/checkpoints/scannet.pt\n",
    "!/content/models/normal/bin/pip install -r /content/3dgs-priors/geometry-priors/normal_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1950fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SRN cars dataset\n",
    "%cd /content\n",
    "!mkdir SRN\n",
    "%cd /content/SRN\n",
    "!mkdir srn_cars\n",
    "%cd /content/SRN/srn_cars\n",
    "!gdown --id 19yDsEJjx9zNpOKz9o6AaK-E8ED6taJWU -O cars.zip\n",
    "!unzip cars.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed74ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch models to process dataset\n",
    "!/content/models/normal/bin/python /content/3dgs-priors/geometry-priors/generate_normal.py --in_folder=\"{in_folder}\" --out_folder=\"{out_folder}\" --save_iter=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ea1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!/content/models/depth/bin/python /content/3dgs-priors/geometry-priors/generate_depth.py --in_folder=\"{in_folder}\" --out_folder=\"{out_folder}\" --save_iter=30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload generated dataset to HuggingFace\n",
    "login(token=hf_token)\n",
    "\n",
    "# Dataset follow ShapeNet layout, but are stored in Parquet format isntead of folders (due to performance/rate limiting reasons)\n",
    "parquet_files = glob.glob(os.path.join(out_folder, \"*.parquet\"))\n",
    "print(\"Found {} parquet files to upload\".format(len(parquet_files)))\n",
    "\n",
    "for file_path in parquet_files:\n",
    "    name = os.path.basename(file_path).split('.')[0]    \n",
    "    dataset = load_dataset(\"parquet\", data_files=file_path)    \n",
    "    dataset.push_to_hub(\n",
    "        hf_repo_name, \n",
    "        config_name=name\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
