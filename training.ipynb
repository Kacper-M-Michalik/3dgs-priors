{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "training_dataset = \"cars_priors\"\n",
        "use_lora = False\n",
        "use_pretrained_weights = True\n",
        "use_depth = True\n",
        "use_normal = True\n",
        "model_path = \"/content/gaussian-splatting/experiments_out/\"\n",
        "\n",
        "hf_token = \"\"\n",
        "repo_id = \"MVP-Group-Project/splatter-image-priors\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q0GwvXlY9Dj",
        "outputId": "9aac2e46-cfd9-483a-8b83-9c4bdd7480ef"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Clone necessary repos\n",
        "!git clone --recursive https://github.com/Kacper-M-Michalik/splatter-image.git\n",
        "!git clone --recursive https://github.com/graphdeco-inria/gaussian-splatting.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-qEn89VKsost",
        "outputId": "b5e5283e-4b7f-4389-e296-5efca75d4bc8"
      },
      "outputs": [],
      "source": [
        "# Install model requirements\n",
        "%cd /content/splatter-image\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7dg7ienYSXS",
        "outputId": "335b2e1f-f189-45d8-f6e5-db25cf6ead38"
      },
      "outputs": [],
      "source": [
        "# Get correct package versions\n",
        "%cd /content/gaussian-splatting\n",
        "os.environ['TORCH_CUDA_ARCH_LIST'] = \"7.0;7.5;8.0+PTX\"\n",
        "!pip install -e submodules/diff-gaussian-rasterization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMfX3RcVT6Bp",
        "outputId": "2899a4a7-4ff8-4447-921c-1f0c34822954"
      },
      "outputs": [],
      "source": [
        "# Import necessary packages and verify versions\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from huggingface_hub import login, HfApi\n",
        "\n",
        "print(\"PyTorch Version:\", torch.__version__)\n",
        "print(\"CUDA Version:\", torch.version.cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Finetune existing model to use priors\n",
        "!python /content/splatter-image/train_network.py +dataset={training_dataset} opt.pretrained_hf={use_pretrained_weights} opt.lora_finetune={use_lora} data.use_pred_depth={use_depth} data.use_pred_normal={use_normal}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save weights to huggingface\n",
        "\n",
        "files = []\n",
        "model_path = Path(model_path)\n",
        "\n",
        "# If model data is directly in folder, use that, otherwise we assume the wandb file structure\n",
        "possible_files = [file for file in model_path.glob('*{}'.format(\".pth\"))]\n",
        "if len(possible_files) > 0:\n",
        "    files = [file for file in model_path.iterdir() if file.is_file()]\n",
        "else:\n",
        "    date_folders = sorted([folder for folder in model_path.iterdir() if folder.is_dir()])\n",
        "    \n",
        "    if not date_folders:\n",
        "        print(\"No date folders found.\")\n",
        "    else:\n",
        "        latest_date_folder = date_folders[-1]\n",
        "        print(\"Latest Date: {}\".format(latest_date_folder.name))\n",
        "\n",
        "        time_folders = sorted([folder for folder in latest_date_folder.iterdir() if folder.is_dir()])        \n",
        "        if not time_folders:\n",
        "            print(\"No time folders found inside {}\".format(latest_date_folder.name))\n",
        "        else:  \n",
        "            latest_time_folder = time_folders[-1]\n",
        "            print(f\"Latest Time: {latest_time_folder.name}\")\n",
        "            files = [p for p in latest_time_folder.iterdir() if p.is_file()]\n",
        "\n",
        "login(token=hf_token)\n",
        "api = HfApi()\n",
        "\n",
        "# Upload model\n",
        "for file_path in files:    \n",
        "    # Title upload folder correctly\n",
        "    path_in_repo = \"model\"\n",
        "    if use_depth:\n",
        "        path_in_repo += \"-depth\"\n",
        "    if use_normal:\n",
        "        path_in_repo += \"-normal\"\n",
        "    if use_lora:\n",
        "        path_in_repo += \"-finetune\"    \n",
        "\n",
        "    path_in_repo += \"/\" + os.path.basename(file_path)\n",
        "\n",
        "    # Upload file\n",
        "    api.upload_file(\n",
        "        path_or_fileobj=file_path,\n",
        "        repo_id=repo_id,\n",
        "        repo_type=\"model\",\n",
        "        path_in_repo=path_in_repo,\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
