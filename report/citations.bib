@misc{splatterImage,
      title={Splatter Image: Ultra-Fast Single-View 3D Reconstruction}, 
      author={Stanislaw Szymanowicz and Christian Rupprecht and Andrea Vedaldi},
      year={2024},
      eprint={2312.13150},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.13150}, 
}

@misc{tang2024hisplathierarchical3dgaussian,
      title={HiSplat: Hierarchical 3D Gaussian Splatting for Generalizable Sparse-View Reconstruction}, 
      author={Shengji Tang and Weicai Ye and Peng Ye and Weihao Lin and Yang Zhou and Tao Chen and Wanli Ouyang},
      year={2024},
      eprint={2410.06245},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.06245}, 
}

@misc{shen2024pixelworth3dgaussians,
      title={A Pixel Is Worth More Than One 3D Gaussians in Single-View 3D Reconstruction}, 
      author={Jianghao Shen and Nan Xue and Tianfu Wu},
      year={2024},
      eprint={2405.20310},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.20310}, 
}

@misc{pointCloud,
      title={Learning to Recover 3D Scene Shape from a Single Image}, 
      author={Wei Yin and Jianming Zhang and Oliver Wang and Simon Niklaus and Long Mai and Simon Chen and Chunhua Shen},
      year={2020},
      eprint={2012.09365},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2012.09365}, 
}

@misc{mesh,
      title={Mesh R-CNN}, 
      author={Georgia Gkioxari and Jitendra Malik and Justin Johnson},
      year={2020},
      eprint={1906.02739},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1906.02739}, 
}

@Article{photogrammetry,
AUTHOR = {Kang, Zhizhong and Yang, Juntao and Yang, Zhou and Cheng, Sai},
TITLE = {A Review of Techniques for 3D Reconstruction of Indoor Environments},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {9},
YEAR = {2020},
NUMBER = {5},
ARTICLE-NUMBER = {330},
URL = {https://www.mdpi.com/2220-9964/9/5/330},
ISSN = {2220-9964},
ABSTRACT = {Indoor environment model reconstruction has emerged as a significant and challenging task in terms of the provision of a semantically rich and geometrically accurate indoor model. Recently, there has been an increasing amount of research related to indoor environment reconstruction. Therefore, this paper reviews the state-of-the-art techniques for the three-dimensional (3D) reconstruction of indoor environments. First, some of the available benchmark datasets for 3D reconstruction of indoor environments are described and discussed. Then, data collection of 3D indoor spaces is briefly summarized. Furthermore, an overview of the geometric, semantic, and topological reconstruction of the indoor environment is presented, where the existing methodologies, advantages, and disadvantages of these three reconstruction types are analyzed and summarized. Finally, future research directions, including technique challenges and trends, are discussed for the purpose of promoting future research interest. It can be concluded that most of the existing indoor environment reconstruction methods are based on the strong Manhattan assumption, which may not be true in a real indoor environment, hence limiting the effectiveness and robustness of existing indoor environment reconstruction methods. Moreover, based on the hierarchical pyramid structures and the learnable parameters of deep-learning architectures, multi-task collaborative schemes to share parameters and to jointly optimize each other using redundant and complementary information from different perspectives show their potential for the 3D reconstruction of indoor environments. Furthermore, indoor–outdoor space seamless integration to achieve a full representation of both interior and exterior buildings is also heavily in demand.},
DOI = {10.3390/ijgi9050330}
}

@misc{delaunayTriangulation,
      title={Automatic 3D Reconstruction of Manifold Meshes via Delaunay Triangulation and Mesh Sweeping}, 
      author={Andrea Romanoni and Amaël Delaunoy and Marc Pollefeys and Matteo Matteucci},
      year={2016},
      eprint={1604.06258},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1604.06258}, 
}

@article{marchingCubes,
author = {Newman, Timothy and Yi, Hong},
year = {2006},
month = {10},
pages = {854-879},
title = {A survey of the Marching Cubes algorithm},
volume = {30},
journal = {Computers \& Graphics},
doi = {10.1016/j.cag.2006.07.021}
}

@misc{nerf,
      title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis}, 
      author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
      year={2020},
      eprint={2003.08934},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2003.08934}, 
}

@misc{f3dgaus,
      title={F3D-Gaus: Feed-forward 3D-aware Generation on ImageNet with Cycle-Aggregative Gaussian Splatting}, 
      author={Yuxin Wang and Qianyi Wu and Dan Xu},
      year={2025},
      eprint={2501.06714},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2501.06714}, 
}

@misc{hao2025gaussvideodreamer3dscenegeneration,
      title={GaussVideoDreamer: 3D Scene Generation with Video Diffusion and Inconsistency-Aware Gaussian Splatting}, 
      author={Junlin Hao and Peiheng Wang and Haoyang Wang and Xinggong Zhang and Zongming Guo},
      year={2025},
      eprint={2504.10001},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2504.10001}, 
}

@misc{triplane,
      title={Efficient Geometry-aware 3D Generative Adversarial Networks}, 
      author={Eric R. Chan and Connor Z. Lin and Matthew A. Chan and Koki Nagano and Boxiao Pan and Shalini De Mello and Orazio Gallo and Leonidas Guibas and Jonathan Tremblay and Sameh Khamis and Tero Karras and Gordon Wetzstein},
      year={2022},
      eprint={2112.07945},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.07945}, 
}

@misc{objaversexl,
      title={Objaverse-XL: A Universe of 10M+ 3D Objects}, 
      author={Matt Deitke and Ruoshi Liu and Matthew Wallingford and Huong Ngo and Oscar Michel and Aditya Kusupati and Alan Fan and Christian Laforte and Vikram Voleti and Samir Yitzhak Gadre and Eli VanderBilt and Aniruddha Kembhavi and Carl Vondrick and Georgia Gkioxari and Kiana Ehsani and Ludwig Schmidt and Ali Farhadi},
      year={2023},
      eprint={2307.05663},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2307.05663}, 
}

@misc{objaverse,
      title={Objaverse: A Universe of Annotated 3D Objects}, 
      author={Matt Deitke and Dustin Schwenk and Jordi Salvador and Luca Weihs and Oscar Michel and Eli VanderBilt and Ludwig Schmidt and Kiana Ehsani and Aniruddha Kembhavi and Ali Farhadi},
      year={2022},
      eprint={2212.08051},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.08051}, 
}

@misc{triplanebasedmodel,
      title={LRM: Large Reconstruction Model for Single Image to 3D}, 
      author={Yicong Hong and Kai Zhang and Jiuxiang Gu and Sai Bi and Yang Zhou and Difan Liu and Feng Liu and Kalyan Sunkavalli and Trung Bui and Hao Tan},
      year={2024},
      eprint={2311.04400},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2311.04400}, 
}

@misc{3dgs,
      title={3D Gaussian Splatting for Real-Time Radiance Field Rendering}, 
      author={Bernhard Kerbl and Georgios Kopanas and Thomas Leimkühler and George Drettakis},
      year={2023},
      eprint={2308.04079},
      archivePrefix={arXiv},
      primaryClass={cs.GR},
      url={https://arxiv.org/abs/2308.04079}, 
}

@misc{unet,
      title={U-Net: Convolutional Networks for Biomedical Image Segmentation}, 
      author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
      year={2015},
      eprint={1505.04597},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1505.04597}, 
}

@misc{songunet,
      title={Denoising Diffusion Implicit Models}, 
      author={Jiaming Song and Chenlin Meng and Stefano Ermon},
      year={2022},
      eprint={2010.02502},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2010.02502}, 
}

@inProceedings{xu2019disn,
  title={DISN: Deep Implicit Surface Network for High-quality Single-view 3D Reconstruction},
  author={Xu, Qiangeng and Wang, Weiyue and Ceylan, Duygu and Mech, Radomir and Neumann, Ulrich},
  booktitle={NeurIPS},
  year={2019}
}

@article{ShapeNet,
  author       = {Angel X. Chang and
                  Thomas A. Funkhouser and
                  Leonidas J. Guibas and
                  Pat Hanrahan and
                  Qi{-}Xing Huang and
                  Zimo Li and
                  Silvio Savarese and
                  Manolis Savva and
                  Shuran Song and
                  Hao Su and
                  Jianxiong Xiao and
                  Li Yi and
                  Fisher Yu},
  title        = {ShapeNet: An Information-Rich 3D Model Repository},
  journal      = {CoRR},
  volume       = {abs/1512.03012},
  year         = {2015},
  url          = {http://arxiv.org/abs/1512.03012},
  eprinttype    = {arXiv},
  eprint       = {1512.03012},
  timestamp    = {Fri, 25 Oct 2024 13:31:18 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/ChangFGHHLSSSSX15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{Bae2021,
    title   = {Estimating and Exploiting the Aleatoric Uncertainty in Surface Normal Estimation},
    author  = {Gwangbin Bae and Ignas Budvytis and Roberto Cipolla},
    booktitle = {International Conference on Computer Vision (ICCV)},
    year = {2021}                         
}

@inproceedings{NYUv2,
  author    = {Nathan Silberman, Derek Hoiem, Pushmeet Kohli and Rob Fergus},
  title     = {Indoor Segmentation and Support Inference from RGBD Images},
  booktitle = {ECCV},
  year      = {2012}
}

@inproceedings{qi2018geonet,
  title={Geonet: Geometric neural network for joint depth and surface normal estimation},
  author={Qi, Xiaojuan and Liao, Renjie and Liu, Zhengzhe and Urtasun, Raquel and Jia, Jiaya},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={283--291},
  year={2018}
}

@article{qi2020geonet++,
  title={GeoNet++: Iterative Geometric Neural Network with Edge-Aware Refinement for Joint Depth and Surface Normal Estimation},
  author={Qi, Xiaojuan and Liu, Zhengzhe and Liao, Renjie and Torr, Philip HS and Urtasun, Raquel and Jia, Jiaya},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2020},
  publisher={IEEE}
}

@inproceedings{dai2017scannet,
    title={ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes},
    author={Dai, Angela and Chang, Angel X. and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
    booktitle = {Proc. Computer Vision and Pattern Recognition (CVPR), IEEE},
    year = {2017}
}

@article{huang2019framenet,
  title={FrameNet: Learning Local Canonical Frames of 3D Surfaces from a Single RGB Image},
  author={Huang, Jingwei and Zhou, Yichao and Funkhouser, Thomas and Guibas, Leonidas},
  journal={arXiv preprint arXiv:1903.12305},
  year={2019}
}

@incollection{vifIntro,
title = {Chapter 10 - A study on the relationship between depth map quality and stereoscopic image quality using upsampled depth maps},
editor = {Leonidas Deligiannidis and Hamid R. Arabnia},
booktitle = {Emerging Trends in Image Processing, Computer Vision and Pattern Recognition},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {149-160},
year = {2015},
isbn = {978-0-12-802045-6},
doi = {https://doi.org/10.1016/B978-0-12-802045-6.00010-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128020456000107},
author = {Saeed Mahmoudpour and Manbae Kim},
keywords = {Correlation, Depth map, Stereoscopic image, Subjective assessment, Upsampling},
abstract = {Recent advances in 3D technology have made the need for reliable quality evaluation of synthesized virtual views. Using RGB image and the corresponding depth map, a synthesized view can be constructed. Depth map upsampling has gained much interest following the release of time-of-flight cameras. As upsampling can yield artifacts on sharp edges like ringing artifacts and jagged edges near the depth map boundaries, it will degrade the final reconstructed stereoscopic image quality. In this article, several upsampling methods are applied to depth maps. Then, diverse full-reference and no-reference quality assessment tools are utilized to measure the quality of depth maps obtained from selected upsampling approaches. Furthermore, subjective test is performed to determine the quality of stereoscopic images reconstructed from upsampled depth maps. Finally, the relation between subjective assessment and each objective quality assessment is investigated using correlation coefficients. The evaluation results introduce the objective quality assessment tools that can correctly render human judgement.}
}

@article{vifMetrics,
title = {Survey of natural image enhancement techniques: Classification, evaluation, challenges, and perspectives},
journal = {Digital Signal Processing},
volume = {127},
pages = {103547},
year = {2022},
issn = {1051-2004},
doi = {https://doi.org/10.1016/j.dsp.2022.103547},
url = {https://www.sciencedirect.com/science/article/pii/S1051200422001646},
author = {Xinwei Liu and Marius Pedersen and Renfang Wang},
keywords = {Image enhancement, Image quality metric, Visual quality, Database},
abstract = {Image enhancement is an essential technique used in many imaging applications. The main motivation of image enhancement is processing an image to be more suitable for specific utilization. Various image enhancement methods have been proposed in the existing literature. On the one hand, a variety of enhancement techniques make the classification more complex. On the other hand, the lack of image quality metrics specifically designed for enhanced images and the number of enhanced image quality databases as well as subjective data (ground truth) is limited, making the evaluation process difficult. This survey aims to guide the image enhancement research community to fill the above-mentioned gap and develop better and robust enhancement techniques. This survey 1) summarizes previous surveys of image enhancement techniques and existing classifications; 2) classifies the amount of techniques and analyzes their components, including how the performance has been evaluated; 3) surveys and recommends image quality metrics and databases that were designed for enhanced images; 4) discusses the challenges for image enhancement and its evaluation issues; and 5) proposes perspectives for the development of future image enhancement algorithms. This survey mainly focuses on image enhancement techniques that improve the perceived quality of natural images.}
}

@misc{Gatis_rembg_2025,
  author =       {Daniel Gatis},
  title =        {rembg},
  howpublished = {\url{https://github.com/danielgatis/rembg}},
  year =         {2025},
  note =         {Version 2.0.66}
}

@inproceedings{kim2022inspyrenet,
  title={Revisiting Image Pyramid Structure for High Resolution Salient Object Detection},
  author={Kim, Taehun and Kim, Kunhee and Lee, Joonyeong and Cha, Dongmin and Lee, Jiho and Kim, Daijin},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  pages={108--124},
  year={2022}
}

@article{zheng2024birefnet,
  title={Bilateral Reference for High-Resolution Dichotomous Image Segmentation},
  author={Zheng, Peng and Gao, Dehong and Fan, Deng-Ping and Liu, Li and Laaksonen, Jorma and Ouyang, Wanli and Sebe, Nicu},
  journal={CAAI Artificial Intelligence Research},
  volume = {3},
  pages = {9150038},
  year={2024}
}

@misc{wu2019detectron2,
  author =       {Yuxin Wu and Alexander Kirillov and Francisco Massa and
                  Wan-Yen Lo and Ross Girshick},
  title =        {Detectron2},
  howpublished = {\url{https://github.com/facebookresearch/detectron2}},
  year =         {2019}
}

@article{kirillov2023segany,
  title={Segment Anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Doll{\'a}r, Piotr and Girshick, Ross},
  journal={arXiv:2304.02643},
  year={2023}
}

@misc{srn,
      title={Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations}, 
      author={Vincent Sitzmann and Michael Zollhöfer and Gordon Wetzstein},
      year={2020},
      eprint={1906.01618},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1906.01618}, 
}